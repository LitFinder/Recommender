2024-06-17 23:32:30.853469: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-17 23:32:33.720734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/regy/miniconda3/envs/tf/lib/
2024-06-17 23:32:33.721070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/regy/miniconda3/envs/tf/lib/
2024-06-17 23:32:33.721127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-06-17 23:32:34,816 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2024-06-17 23:32:34,816 - INFO - Added job "scheduled_task" to job store "default"
2024-06-17 23:32:34,816 - INFO - Scheduler started
INFO:     Started server process [5858]
INFO:     Waiting for application startup.
/home/regy/miniconda3/envs/tf/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.
  warn_deprecated(
2024-06-17 23:32:44,885 - INFO - Use pytorch device_name: cuda
2024-06-17 23:32:44,886 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
/home/regy/miniconda3/envs/tf/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2024-06-17 23:32:52,482 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2024-06-17 23:32:52,574 - INFO - Collection langchain is not created.
2024-06-17 23:33:10.793890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:33:10.868714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:33:10.868865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:33:10.871648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-17 23:33:10.877425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:33:10.877613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:33:10.877799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:33:10.901459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:33:10.901976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:33:10.902064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2024-06-17 23:33:10.902231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:33:10.902521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1663 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:52474 - "POST /add_rating/ HTTP/1.1" 200 OK
2024-06-17 23:34:21.671493: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-17 23:34:22.900361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/regy/miniconda3/envs/tf/lib/
2024-06-17 23:34:22.900539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/regy/miniconda3/envs/tf/lib/
2024-06-17 23:34:22.900561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-06-17 23:34:26.290187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:34:26.306955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:34:26.307094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:34:26.307445: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-17 23:34:26.310217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:34:26.310407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:34:26.310505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:34:26.514924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:34:26.515160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:34:26.515229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2024-06-17 23:34:26.515312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:34:26.515394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
2024-06-17 23:34:29.178629: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fd269a55cd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-06-17 23:34:29.178893: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6
2024-06-17 23:34:29.202852: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-06-17 23:34:29.538632: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-06-17 23:34:29.924911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.
Number of users: 138940, Number of books: 9909, Min Rating: 0.0, Max Rating: 5.0
Load the previously saved model
Train a new model
  1/310 [..............................] - ETA: 44s 13/310 [>.............................] - ETA: 1s  24/310 [=>............................] - ETA: 1s 34/310 [==>...........................] - ETA: 1s 44/310 [===>..........................] - ETA: 1s 54/310 [====>.........................] - ETA: 1s 64/310 [=====>........................] - ETA: 1s 76/310 [======>.......................] - ETA: 1s 88/310 [=======>......................] - ETA: 1s100/310 [========>.....................] - ETA: 1s112/310 [=========>....................] - ETA: 0s124/310 [===========>..................] - ETA: 0s136/310 [============>.................] - ETA: 0s148/310 [=============>................] - ETA: 0s159/310 [==============>...............] - ETA: 0s171/310 [===============>..............] - ETA: 0s182/310 [================>.............] - ETA: 0s194/310 [=================>............] - ETA: 0s207/310 [===================>..........] - ETA: 0s219/310 [====================>.........] - ETA: 0s231/310 [=====================>........] - ETA: 0s242/310 [======================>.......] - ETA: 0s254/310 [=======================>......] - ETA: 0s266/310 [========================>.....] - ETA: 0s278/310 [=========================>....] - ETA: 0s289/310 [==========================>...] - ETA: 0s301/310 [============================>.] - ETA: 0s310/310 [==============================] - 2s 5ms/step
INFO:     127.0.0.1:52490 - "POST /colabUser/?user_id=ygbenerrraaaaaa&amount=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58934 - "POST /add_rating/ HTTP/1.1" 200 OK
2024-06-17 23:36:00.877577: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-17 23:36:01.689968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/regy/miniconda3/envs/tf/lib/
2024-06-17 23:36:01.690120: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/regy/miniconda3/envs/tf/lib/
2024-06-17 23:36:01.690177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-06-17 23:36:04.601237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:36:04.631748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:36:04.631884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:36:04.632271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-17 23:36:04.633597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:36:04.633699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:36:04.633863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:36:04.775081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:36:04.775251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:36:04.775310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2024-06-17 23:36:04.775394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:36:04.775517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
2024-06-17 23:36:06.554775: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x46afe70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-06-17 23:36:06.554906: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6
2024-06-17 23:36:06.560398: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-06-17 23:36:06.637340: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-06-17 23:36:06.887385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.
Number of users: 138941, Number of books: 9909, Min Rating: 0.0, Max Rating: 5.0
Load the previously saved model
Train a new model
INFO:     Shutting down
INFO:     Waiting for application shutdown.
2024-06-17 23:37:32,571 - INFO - Scheduler has been shut down
INFO:     Application shutdown complete.
INFO:     Finished server process [5858]
2024-06-17 23:37:34.252294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-17 23:37:35.083293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/regy/miniconda3/envs/tf/lib/
2024-06-17 23:37:35.083438: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/regy/miniconda3/envs/tf/lib/
2024-06-17 23:37:35.083461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-06-17 23:37:35,643 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2024-06-17 23:37:35,643 - INFO - Added job "scheduled_task" to job store "default"
2024-06-17 23:37:35,643 - INFO - Scheduler started
INFO:     Started server process [6723]
INFO:     Waiting for application startup.
/home/regy/miniconda3/envs/tf/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.
  warn_deprecated(
2024-06-17 23:37:41,072 - INFO - Use pytorch device_name: cuda
2024-06-17 23:37:41,072 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
/home/regy/miniconda3/envs/tf/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2024-06-17 23:37:47,607 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2024-06-17 23:37:47,704 - INFO - Collection langchain is not created.
2024-06-17 23:38:07.113461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:38:07.136630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:38:07.136807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:38:07.137369: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-17 23:38:07.139615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:38:07.139772: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:38:07.139866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:38:07.144213: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:38:07.144406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:38:07.144490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2024-06-17 23:38:07.144619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2024-06-17 23:38:07.144722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1663 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     180.241.46.35:0 - "GET / HTTP/1.1" 200 OK
INFO:     103.168.190.2:0 - "GET / HTTP/1.1" 200 OK
INFO:     103.168.190.2:0 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     103.168.190.2:0 - "GET /docs HTTP/1.1" 200 OK
INFO:     103.168.190.2:0 - "GET /openapi.json HTTP/1.1" 200 OK
INFO:     180.241.46.35:0 - "GET /docs HTTP/1.1" 200 OK
INFO:     180.241.46.35:0 - "GET /openapi.json HTTP/1.1" 200 OK
INFO:     125.166.117.182:0 - "GET / HTTP/1.1" 200 OK
INFO:     125.166.117.182:0 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     180.241.46.35:0 - "POST /add_rating/ HTTP/1.1" 200 OK
  1/310 [..............................] - ETA: 49s 10/310 [..............................] - ETA: 1s  18/310 [>.............................] - ETA: 1s 26/310 [=>............................] - ETA: 1s 34/310 [==>...........................] - ETA: 1s 42/310 [===>..........................] - ETA: 1s 52/310 [====>.........................] - ETA: 1s 64/310 [=====>........................] - ETA: 1s 75/310 [======>.......................] - ETA: 1s 85/310 [=======>......................] - ETA: 1s 97/310 [========>.....................] - ETA: 1s110/310 [=========>....................] - ETA: 1s122/310 [==========>...................] - ETA: 0s134/310 [===========>..................] - ETA: 0s145/310 [=============>................] - ETA: 0s156/310 [==============>...............] - ETA: 0s168/310 [===============>..............] - ETA: 0s180/310 [================>.............] - ETA: 0s192/310 [=================>............] - ETA: 0s205/310 [==================>...........] - ETA: 0s218/310 [====================>.........] - ETA: 0s232/310 [=====================>........] - ETA: 0s243/310 [======================>.......] - ETA: 0s255/310 [=======================>......] - ETA: 0s267/310 [========================>.....] - ETA: 0s280/310 [==========================>...] - ETA: 0s293/310 [===========================>..] - ETA: 0s306/310 [============================>.] - ETA: 0s310/310 [==============================] - 2s 5ms/step
INFO:     180.241.46.35:0 - "POST /colabUser/?user_id=yahsudahla&amount=1000 HTTP/1.1" 200 OK
INFO:     103.160.183.15:0 - "GET / HTTP/1.1" 200 OK
INFO:     103.160.183.15:0 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     103.160.183.15:0 - "GET /docs HTTP/1.1" 200 OK
INFO:     103.160.183.15:0 - "GET /openapi.json HTTP/1.1" 200 OK
  1/310 [..............................] - ETA: 6s 15/310 [>.............................] - ETA: 1s 28/310 [=>............................] - ETA: 1s 42/310 [===>..........................] - ETA: 1s 55/310 [====>.........................] - ETA: 0s 66/310 [=====>........................] - ETA: 0s 78/310 [======>.......................] - ETA: 0s 89/310 [=======>......................] - ETA: 0s101/310 [========>.....................] - ETA: 0s115/310 [==========>...................] - ETA: 0s128/310 [===========>..................] - ETA: 0s139/310 [============>.................] - ETA: 0s150/310 [=============>................] - ETA: 0s162/310 [==============>...............] - ETA: 0s173/310 [===============>..............] - ETA: 0s185/310 [================>.............] - ETA: 0s197/310 [==================>...........] - ETA: 0s209/310 [===================>..........] - ETA: 0s221/310 [====================>.........] - ETA: 0s232/310 [=====================>........] - ETA: 0s246/310 [======================>.......] - ETA: 0s259/310 [========================>.....] - ETA: 0s273/310 [=========================>....] - ETA: 0s288/310 [==========================>...] - ETA: 0s304/310 [============================>.] - ETA: 0s310/310 [==============================] - 1s 4ms/step
INFO:     103.160.183.15:0 - "POST /colabUser/?user_id=A3NDZCQ9D9T2XM&amount=10 HTTP/1.1" 200 OK
  1/310 [..............................] - ETA: 8s  8/310 [..............................] - ETA: 2s 16/310 [>.............................] - ETA: 2s 23/310 [=>............................] - ETA: 2s 32/310 [==>...........................] - ETA: 1s 40/310 [==>...........................] - ETA: 1s 48/310 [===>..........................] - ETA: 1s 55/310 [====>.........................] - ETA: 1s 63/310 [=====>........................] - ETA: 1s 72/310 [=====>........................] - ETA: 1s 80/310 [======>.......................] - ETA: 1s 95/310 [========>.....................] - ETA: 1s110/310 [=========>....................] - ETA: 1s124/310 [===========>..................] - ETA: 1s136/310 [============>.................] - ETA: 0s149/310 [=============>................] - ETA: 0s162/310 [==============>...............] - ETA: 0s177/310 [================>.............] - ETA: 0s190/310 [=================>............] - ETA: 0s206/310 [==================>...........] - ETA: 0s217/310 [====================>.........] - ETA: 0s229/310 [=====================>........] - ETA: 0s238/310 [======================>.......] - ETA: 0s246/310 [======================>.......] - ETA: 0s253/310 [=======================>......] - ETA: 0s261/310 [========================>.....] - ETA: 0s271/310 [=========================>....] - ETA: 0s281/310 [==========================>...] - ETA: 0s292/310 [===========================>..] - ETA: 0s302/310 [============================>.] - ETA: 0s310/310 [==============================] - 2s 5ms/step
INFO:     103.160.183.15:0 - "POST /colabUser/?user_id=A3NDZCQ9D9T2XM&amount=10 HTTP/1.1" 200 OK
